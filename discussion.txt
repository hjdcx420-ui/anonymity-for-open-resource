In recent research, significant efforts have been made to enhance multi-agent collaboration within recommendation systems. However, many of these works still face challenges in effectively unifying collaboration signals across tasks and processes, and they often overlook the dynamic nature of multi-agent negotiation.

[1] and [2] focus on cross-domain and cross-process recommendation, aiming to optimize performance across different recommendation tasks. Despite their contributions, these works lack a unified collaboration signal that can effectively link the various tasks. The absence of a coordinated signal network limits their ability to handle the complexity of multi-agent interactions in a holistic manner. Furthermore, these studies treat tasks in isolation without considering the dynamic interdependencies between them. [3], while also targeting cross-process collaboration, attempts to provide a unified signal between different processes. However, the heterogeneity among processes results in discrete considerations of user states. This leads to a feedback-driven, mechanical incentive structure that remains rigid and unable to adapt dynamically to the diverse actions of multiple agents. Their unified signal network, although a step forward, struggles to accommodate the complexity of heterogeneous agent actions and cannot effectively harmonize the multi-agent negotiation process across tasks. Other works in multi-agent collaboration, such as [4] which leverages social networks to integrate different community cultures, and [5] and [6] that enhance group recommendation by strengthening user representations within groups, still fall under the category of static user representation enhancement. These approaches focus on improving recommendations based on fixed group or community-level data, but they fail to account for the dynamic nature of collaboration. In these methods, user interactions and negotiations are not dynamically optimized, leading to a limited understanding of how agents can collaborate and adapt in real-time scenarios.

In contrast, our work advances these studies by introducing dynamic collaboration mechanisms through joint actions and unified incentives. This approach not only facilitates a more adaptive and responsive recommendation process but also addresses the dynamic nature of multi-agent systems. By incorporating flexible signal transmission and coordinated incentives, our framework enables more efficient and robust optimization in complex recommendation tasks, pushing the boundaries of static user representation enhancement and achieving true multi-agent collaboration.

[1] Zhao Y, Zhou C, Cao J, et al. Multi-scenario combination based on multi-agent reinforcement learning to optimize the advertising recommendation system[C]//2024 5th International Conference on Artificial Intelligence and Electromechanical Automation (AIEA). IEEE, 2024: 190-194.
[2] Wang Z, Yu Y, Zheng W, et al. Macrec: A multi-agent collaboration framework for recommendation[C]//Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval. 2024: 2760-2764.
[3]He X, An B, Li Y, et al. Learning to collaborate in multi-module recommendation via multi-agent reinforcement learning without communication[C]//Proceedings of the 14th ACM Conference on Recommender Systems. 2020: 210-219.
[4] Birukou A, Blanzieri E, Giorgini P. Implicit: a multi-agent recommendation system for web search[J]. Autonomous Agents and Multi-Agent Systems, 2012, 24(1): 141-174.
[5] Huang Z, Liu Y, Zhan C, et al. A novel group recommendation model with two-stage deep learning[J]. IEEE Transactions on Systems, Man, and Cybernetics: Systems, 2021, 52(9): 5853-5864.
[6] Chen Y L, Cheng L C, Chuang C N. A group recommendation system with consideration of interactions among group members[J]. Expert systems with applications, 2008, 34(3): 2082-2090.